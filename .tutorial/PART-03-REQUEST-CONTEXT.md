# Part 03: Request Context

## Goal
Learn how the plugin gathers buffer data, rules, and selection context before calling the model.

## See Also
See also: [Overview](OVERVIEW.md), [Walkthrough: Adding a Language](WALKTHROUGH.md), [Prev: Part 02](PART-02-ENTRY-POINT-STATE.md), [Next: Part 04](PART-04-PROMPTS.md).

## Key Files
- `lua/99/request-context.lua`
- `lua/99/utils.lua`

## Mini Diagram
```
buffer + rules + range -> RequestContext -> ai_context[] -> prompt
```

## Longer Trace: Context Assembly
1. `RequestContext.from_current_buffer` reads buffer number, path, and filetype.
2. It normalizes `typescriptreact` to `typescript` for consistent queries.
3. A temp file path is generated by `utils.random_file()`.
4. `md_file_names` are copied from `_99_state.md_files`.
5. When a request starts, `RequestContext:finalize` reads markdown files from the directory tree.
6. If a range is set, it appends location and selected text to `ai_context`.
7. Finally, it appends the temp file contract block.

## Inline Callouts
- `lua/99/request-context.lua` `RequestContext.from_current_buffer` sets buffer metadata and logger ID.
- `lua/99/request-context.lua` `_read_md_files` walks from file directory up to `vim.uv.cwd()`.
- `lua/99/request-context.lua` `add_agent_rules` injects `SKILL.md` contents into the AI context.
- `lua/99/request-context.lua` `finalize` adds location, range text, and temp file instructions.
- `lua/99/request-context.lua` `save_prompt` writes a `-prompt` file for debugging.
- `lua/99/utils.lua` `random_file` is the temp file generator.

## Code Snapshot
File: `lua/99/request-context.lua`
```lua
function RequestContext:finalize()
  self:_read_md_files()
  if self.range then
    table.insert(self.ai_context, self._99.prompts.get_file_location(self))
    table.insert(self.ai_context, self._99.prompts.get_range_text(self.range))
  end
  table.insert(self.ai_context, self._99.prompts.tmp_file_location(self.tmp_file))
  return self
end
```

## Practical Notes
- The context object is the only source of truth for what is sent to the model.
- Rule injection is explicit, so the prompt is always explainable.

## Performance Checklist
- Cache markdown rule files by path and mtime to avoid re-reading on every request.
- Avoid embedding full file content for very large files; consider a size cap.
- Reuse `ai_context` tables where safe to reduce allocations.
- Minimize repeated calls to `vim.uv.cwd()` in tight paths.

## Profiling Snippet
File: `lua/99/request-context.lua`
```lua
local start = vim.uv.hrtime()
context:finalize()
local ms = (vim.uv.hrtime() - start) / 1e6
vim.notify(string.format("context:finalize %.2fms", ms))
```

## Quick Exercise
1. Open `lua/99/request-context.lua` and trace `_read_md_files`.
2. Add a temporary `AGENTS.md` in a parent directory and confirm it is appended.
3. Search logs to see the prompt file saved with `-prompt` suffix.
